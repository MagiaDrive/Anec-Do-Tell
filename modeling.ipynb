{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9992865,"sourceType":"datasetVersion","datasetId":6150204}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"brabus61/joke-generator\")\nmodel = AutoModelForCausalLM.from_pretrained(\"brabus61/joke-generator\", from_tf=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:18:00.259827Z","iopub.execute_input":"2024-11-24T17:18:00.260227Z","iopub.status.idle":"2024-11-24T17:18:37.032018Z","shell.execute_reply.started":"2024-11-24T17:18:00.260183Z","shell.execute_reply":"2024-11-24T17:18:37.030552Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"066508afe7034a84be2db404ace6046d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9929a6e10e68403da29de295f4342d42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/27.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38e7bfb9e42c486fabfd38592283764b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/145k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c2b18e4104e4322ab52bbc78f7c01eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/131 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bb4c181474640f192421ffa7defeeca"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/868 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c33cd868345d458da0a65bb8ee0d8aa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/356M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4382682bd4e04a76bf8c48212ef76aed"}},"metadata":{}},{"name":"stderr","text":"All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n\nSome weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset, get_dataset_split_names\n\n\ndataset = load_dataset(\"json\", data_files=\"/kaggle/input/anecdotsforproject/final_dataset.json\", split=\"train\")\ndataset=dataset.train_test_split(test_size=0.2)\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:18:37.034138Z","iopub.execute_input":"2024-11-24T17:18:37.034510Z","iopub.status.idle":"2024-11-24T17:18:38.066738Z","shell.execute_reply.started":"2024-11-24T17:18:37.034474Z","shell.execute_reply":"2024-11-24T17:18:38.065387Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02972aba09044230ba737d928308223d"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'text'],\n        num_rows: 4860\n    })\n    test: Dataset({\n        features: ['id', 'text'],\n        num_rows: 1215\n    })\n})"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def tokenize(element):\n    outputs = tokenizer(\n        element[\"text\"],\n        truncation=True,\n        max_length=128,\n        return_overflowing_tokens=True,\n        return_length=True,\n    )\n    input_batch = []\n    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n        if length == 128:\n            input_batch.append(input_ids)\n    return {\"input_ids\": input_batch}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:18:38.068246Z","iopub.execute_input":"2024-11-24T17:18:38.068706Z","iopub.status.idle":"2024-11-24T17:18:38.075805Z","shell.execute_reply.started":"2024-11-24T17:18:38.068647Z","shell.execute_reply":"2024-11-24T17:18:38.074462Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"tokenized_dataset = dataset.map(\n    tokenize, batched=True, remove_columns=dataset[\"train\"].column_names\n)\ntokenized_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:18:38.078401Z","iopub.execute_input":"2024-11-24T17:18:38.078991Z","iopub.status.idle":"2024-11-24T17:18:39.792961Z","shell.execute_reply.started":"2024-11-24T17:18:38.078953Z","shell.execute_reply":"2024-11-24T17:18:39.791564Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4860 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f5a24874e624021aad6e51cb867fbb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1215 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ba95cebac2d4f45916f892ae21e1165"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids'],\n        num_rows: 2812\n    })\n    test: Dataset({\n        features: ['input_ids'],\n        num_rows: 661\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"tokenized_dataset[\"train\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:18:39.794496Z","iopub.execute_input":"2024-11-24T17:18:39.795151Z","iopub.status.idle":"2024-11-24T17:18:39.807014Z","shell.execute_reply.started":"2024-11-24T17:18:39.795096Z","shell.execute_reply":"2024-11-24T17:18:39.805508Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [33,\n  1164,\n  88,\n  297,\n  1553,\n  262,\n  453,\n  12,\n  394,\n  258,\n  1325,\n  744,\n  1214,\n  12,\n  293,\n  789,\n  1258,\n  659,\n  769,\n  350,\n  556,\n  14,\n  325,\n  939,\n  1948,\n  282,\n  326,\n  265,\n  3221,\n  941,\n  3975,\n  769,\n  350,\n  556,\n  296,\n  265,\n  1742,\n  1022,\n  1535,\n  502,\n  902,\n  428,\n  292,\n  14,\n  325,\n  519,\n  727,\n  323,\n  265,\n  354,\n  1123,\n  389,\n  73,\n  350,\n  556,\n  12,\n  748,\n  1357,\n  265,\n  580,\n  3184,\n  3004,\n  285,\n  12,\n  311,\n  748,\n  1357,\n  487,\n  457,\n  12,\n  1385,\n  323,\n  791,\n  496,\n  645,\n  1202,\n  3232,\n  474,\n  325,\n  317,\n  258,\n  769,\n  350,\n  556,\n  635,\n  325,\n  472,\n  3106,\n  89,\n  287,\n  386,\n  635,\n  325,\n  55,\n  861,\n  12,\n  1114,\n  12,\n  1505,\n  296,\n  841,\n  323,\n  470,\n  270,\n  1062,\n  459,\n  325,\n  12,\n  552,\n  265,\n  769,\n  350,\n  556,\n  292,\n  2008,\n  12,\n  325,\n  53,\n  78,\n  2421,\n  3915,\n  12,\n  367,\n  487,\n  3975,\n  496,\n  645,\n  1202]}"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:18:39.808768Z","iopub.execute_input":"2024-11-24T17:18:39.809304Z","iopub.status.idle":"2024-11-24T17:18:39.838120Z","shell.execute_reply.started":"2024-11-24T17:18:39.809244Z","shell.execute_reply":"2024-11-24T17:18:39.836897Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\nargs = TrainingArguments(\n   output_dir=\"example_trainer\",\n    evaluation_strategy = \"epoch\", \n    learning_rate=2e-5,  \n    per_device_train_batch_size=16, \n    per_device_eval_batch_size=16, \n    num_train_epochs=3,\n    weight_decay=0.01, \n    report_to = 'tensorboard',\n    \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:18:39.840173Z","iopub.execute_input":"2024-11-24T17:18:39.840699Z","iopub.status.idle":"2024-11-24T17:18:39.919815Z","shell.execute_reply.started":"2024-11-24T17:18:39.840644Z","shell.execute_reply":"2024-11-24T17:18:39.918509Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"trainer = Trainer(   \n    model, \n    args,  \n    train_dataset=tokenized_dataset[\"train\"].select(range(1000)),  \n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:18:39.921062Z","iopub.execute_input":"2024-11-24T17:18:39.921379Z","iopub.status.idle":"2024-11-24T17:18:40.300882Z","shell.execute_reply.started":"2024-11-24T17:18:39.921346Z","shell.execute_reply":"2024-11-24T17:18:40.299565Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:18:40.302029Z","iopub.execute_input":"2024-11-24T17:18:40.302342Z","iopub.status.idle":"2024-11-24T18:03:43.749984Z","shell.execute_reply.started":"2024-11-24T17:18:40.302312Z","shell.execute_reply":"2024-11-24T18:03:43.748896Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 44:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>nan</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=189, training_loss=0.0, metrics={'train_runtime': 2701.7004, 'train_samples_per_second': 1.11, 'train_steps_per_second': 0.07, 'total_flos': 195969024000000.0, 'train_loss': 0.0, 'epoch': 3.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T18:05:29.540860Z","iopub.execute_input":"2024-11-24T18:05:29.541271Z","iopub.status.idle":"2024-11-24T18:08:30.430949Z","shell.execute_reply.started":"2024-11-24T18:05:29.541237Z","shell.execute_reply":"2024-11-24T18:08:30.429671Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [42/42 02:53]\n    </div>\n    "},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': nan,\n 'eval_runtime': 180.8763,\n 'eval_samples_per_second': 3.654,\n 'eval_steps_per_second': 0.232,\n 'epoch': 3.0}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\npipe = pipeline(\n    \"text-generation\", model=\"brabus61/joke-generator\", device=device)\npipe(\"What kind of pig can you ignore at a party?\", num_return_sequences=1[0][\"generated_text\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}